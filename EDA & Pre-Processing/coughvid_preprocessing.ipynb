{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing on Coughvid dataset\n",
    "\n",
    "This notebook describes the pre-processing steps applied on the Coughvid dataset. These include:\n",
    "\n",
    "1. Conversion to .wav format\n",
    "2. Filtering cough_detected < 0.8.\n",
    "3. Filtering \"symptomatic\" and unlabelled.\n",
    "4. Downsampling to 16khz.\n",
    "5. Standardising to 10 seconds by padding/cropping.\n",
    "6. Augmenting the binary labels and saving into a single .npz file.\n",
    "7. Importing data into a tensorflow format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#                            Imports                                   #\n",
    "########################################################################\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Audio files processing\n",
    "import wave\n",
    "import librosa\n",
    "\n",
    "# Manipualting File paths\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#                           Data Paths                                 #\n",
    "########################################################################\n",
    "\n",
    "# Path to folder containing the data (can be used in both Linux and Windows)\n",
    "data_path = Path(Path.cwd().parent, \"datasets\", \"coughvid_dataset_updated\", \"dataset_cleaned_labelled\")\n",
    "print(f\"Data folder: {data_path}\")\n",
    "\n",
    "data_wav = Path(Path.cwd().parent, \"datasets\", \"coughvid_dataset_updated\", \"dataset_wav\")\n",
    "print(f\"Data .wav folder: {data_wav}\")\n",
    "\n",
    "data_npz_16k = Path(Path.cwd().parent, \"datasets\", \"coughvid_dataset_updated\", \"dataset_npz_16k\")\n",
    "print(f\"Data npz 12k folder: {data_npz_16k}\")\n",
    "\n",
    "metadata_summary_path = os.path.join(data_path, 'metadata.csv')\n",
    "print(f\"Data summary file: {metadata_summary_path}\")\n",
    "\n",
    "metadata = pd.read_csv(metadata_summary_path, delimiter = ',')\n",
    "\n",
    "n_samples = metadata.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to .wav files\n",
    "\n",
    "The .webm and .ogg files are converted to .wav files using the command line utility command os.system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converted webm and ogg files to wav\n",
    "\n",
    "file_names = metadata.uuid.to_numpy()\n",
    "n = file_names.shape[0]\n",
    "\n",
    "for counter, name in enumerate(file_names):\n",
    "    \n",
    "    if (counter%1000 == 0):\n",
    "        print(\"Finished {0}/{1}\".format(counter,len(names_to_convert)))\n",
    "    if os.path.isfile(data_folder + name + '.webm'):\n",
    "        os.system('cmd /c \"ffmpeg -i {0} {1}\"'.format(data_folder+name+\".webm\", data_folder+name+\".wav\"))\n",
    "    elif os.path.isfile(data_folder + name + '.ogg'):\n",
    "        os.system('cmd /c \"ffmpeg -i {0} {1}\"'.format(data_folder+name+\".ogg\", data_folder+name+\".wav\"))\n",
    "    else:\n",
    "        print(\"Error: No file name {0}\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Filtering of samples with cough_detected < 0.8, \"symptomatic\" label and those which do not have a label is done in Excel. The filtered csv is then imported here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filtered_path = os.path.join(data_path, 'metadata_filtered.csv')\n",
    "print(f\"Data summary file: {metadata_summary_path}\")\n",
    "\n",
    "metadata = pd.read_csv(metadata_filtered_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling and Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#                       Data Downsampling                              #\n",
    "########################################################################\n",
    "\n",
    "sample_rate = 16000\n",
    "length = sample_rate * 10 # 10 seconds\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, file in enumerate(metadata[\"uuid\"]):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"Completed {i} files\")\n",
    "       \n",
    "    x, _ = librosa.load(Path(data_wav, file + \".wav\"), sr=sample_rate)\n",
    "    l = x.shape[0]\n",
    "    \n",
    "    if l >= length:\n",
    "        x = x[0:length]\n",
    "    else:\n",
    "        x = np.pad(x, (0,length-l), 'constant')\n",
    "    \n",
    "    data.append(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment binary labels and save as .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1 if y==\"COVID-19\" else 0 for y in metadata[\"status\"] ])\n",
    "np.savez(Path(data_npz_12k.parent,\"coughvid_16k.npz\"), x=data, y=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into a tensorflow format\n",
    "\n",
    "These can then be split into train/valid/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#                           Data Loading                               #\n",
    "########################################################################\n",
    "\n",
    "with np.load(Path(data_npz_12k.parent,\"coughvid_12k.npz\")) as data:\n",
    "    X = data[\"x\"]\n",
    "    y = data[\"y\"]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
